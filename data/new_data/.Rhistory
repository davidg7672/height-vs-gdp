phat1 = new_method_sample_s / new_method_sample
phat2 = conventional_sample_s / conventional_sample
conventional = 2500
new_method = 2500
conventional_sample = 100
conventional_sample_s = 78
new_method_sample = 100
new_method_sample_s = 83
phat1 = new_method_sample_s / new_method_sample
phat2 = conventional_sample_s / conventional_sample
result_phat1 = sqrt(phat1 * (1 -phat1) / new_method_sample)
result_phat2 = sqrt(phat2 * (1 -phat2) / conventional_sample)
se = sqrt(result_phat1 + result_phat2)
alpha = 0.05 / 2
zcrit = qnorm(1 - alpha)
moe = se * zcrit
lower = (phat1 - phat2) - moe
upper = (phat1 - phat2) + moe
mu = 6 / sqrt(5)
mu = 6 / sqrt(5)
# 1
1 - pnorm(210, 200, 6)
se = 6 / sqrt(5)
se = 6 / sqrt(40)
1 - pnorm(210, 200, se)
1 - pnorm(210, 200, se)
# 1
1 - pnorm(210, 200, 6)
# 1
1 - pnorm(210, 200, 6)
# 2
1 - pnorm(210, 200, 6/sqrt(5))
# 3
1 - pnorm(210, 200, 6/sqrt(40))
# 2
1 - pnorm(210, 200, 6/sqrt(5))
# 3
1 - pnorm(210, 200, 6/sqrt(40))
# 3
pnorm(210, 200, 6/sqrt(40))
1 - qt(t, df - 1)
# R Practice with teh t-distribution
t = 1.6
df = 14
1 - pt(t, df - 1)
pt(t, df - 1)
pt(t, 14)
1 - pt(1.6, 14)
qt(0.99, 19)
1 - pt(2.30, 10)
# 2
qt(.10, 15)
# 3
qt(0.025, 20)
#1
1 - pt(2.30, 10)
# 2
qt(.10, 15)
# 3
qt(0.025, 20)
# 2
qt(.9, 15)
# 3
qt(0.025, 20)
#example hypothesis test for sample means
# h0: µ = 70 hA: µ ≠ 70
n = 45
xbar = 63
s = 22
se = s / sqrt(n)
df = n - 1
test_statistic = (xbar - 70) / se
p_value = 2 * pt(-2.134, 44)
# setting up 95 confidence interval
lower = xbar - test_statistic * se
upper = xbar + test_statistic * se
# setting up 95 confidence interval
t_crit = qt(0.975, df)
lower = xbar - t_crit * se #
upper = xbar + t_crit * se #
n = 300
phat = 0.5
moe = 1.96 * sqrt(phat * ((1 - phat)) / n)
moe = 1.96 * sqrt(phat * ((1 - phat)) / n)
# 1
n = 400
phat = 0.5
moe = 1.96 * sqrt(phat * ((1 - phat)) / n)
# moe < 0.05
1.96 * sqrt(0.25/n)
# moe < 0.05
0.05 / 1.96
install.packages("openintro")
library(openintro)
library(openintro)
library(openintro)
library(openintro)
data(acs12)
force(acs12)
View(acs12)
table(acs12)
table(acs12$employment, acs12$gender)
View(acs12)
employed <- subset(acs12, employment == "employed")
View(employed)
table(employed$gender)
prop.test(table(employed$gender), p = c(0.5,0.5))
prop.test(table(employed$gender), p = c(0.5,0.5))
prop.test(table(employed$gender), p = c(0.5, 0.5))
View(acs12)
View(employed)
unique(employed$gender)
table(employed$gender)
prop.test(table(employed$gender), p = c(0.5, 0.5))
p = 0.5
prop.test(table(employed$gender), p = c(0.5, 0.5))
prop.test(x = sum(employed$gender == "Male")
n = length(employed$gender),
prop.test(x = sum(employed$gender == "Male"),
n = length(employed$gender),
p = 0.5,
altnerative = "two.sided")
prop.test(x = sum(employed$gender == "male"),
n = length(employed$gender),
p = 0.5,
altnerative = "two.sided")
prop.test(x = sum(employed$gender == "male"),
n = length(employed$gender),
p = 0.5,
alternative = "two.sided")
over24
# 5
over24 <- subset(acs12, age >= 24)
over24
table(over24)
table(over24)
# 5
over24 <- subset(acs12, age >= 24)
table(over24)
View(over24)
table(over24$edu)
college_plus <- sum(over24$edu %in% c("college", "graduate"))
# 6
noncitizens <- subset(acs12, citizen == "non-citizen")
table(noncitizens$gender)
prop.test(table(noncitizens$gender), p = c(0.5, 0.5))
prop.test(x = sum(employed$gender == "male"),
n = length(employed$gender),
p = 0.5,
alternative = "two.sided")
# exercise 4
library(acs12)
acs12$employment
employed = table(acs12$employment, acs12$gender)
employed = subset(acs12$employment, acs12$gender)
employed = subset(acs12, employment == "employed")
View(employed)
x = sum(employed)
n = length(employed$gender)
phat = x / n
x = sum(employed$gender == "male")
n = length(employed$gender)
phat = x / n
# exercise 4
# h0: p = 0.5
# h1: p ≠ 0.5
alpha = 0.05
employed = subset(acs12, employment == "employed")
x = sum(employed$gender == "male")
n = length(employed$gender)
phat = x / n
se = sqrt((p0 * (1 -p0)) / n)
p0 = 0.5
se = sqrt((p0 * (1 -p0)) / n)
z = (phat - p0) / se
z = (phat - p0) / se
pvalue = 2 * (1 - pnorm(abs(z)))
library(openintro)
data(acs12)
# exercise 4
# h0: p = 0.5
# h1: p ≠ 0.5
alpha = 0.05
employed = subset(acs12, employment == "employed")
x = sum(employed$gender == "male")
n = length(employed$gender)
phat = x / n
p0 = 0.5
se = sqrt((p0 * (1 -p0)) / n)
z = (phat - p0) / se
pvalue = 2 * (1 - pnorm(abs(z))) # 0.00083
View(acs12)
View(acs12)
###############
# exercise 5
# h0: p = 31
# hA: p ≠ 31
over24 = subset(acs12, age >= 24)
View(over24)
x = sum(over24$edu %in% c("college", "graduate"))
n = nrow(over24)
phat = x / n
###############
# exercise 5
# h0: p = 31
# hA: p ≠ 31
over24 = subset(acs12, age >= 24)
x = sum(over24$edu %in% c("college", "graduate"))
n = nrow(over24)
phat = x / n
p0 = 0.31
se = sqrt((p0 * (1 - p0)) / n)
z = (phat - p0) / se
pvalue = 2 * (1 - pnorm(abs(z)))
###############
# exercise 6
# h0: p = .5
# ha: p ≠ .5
non_citizens = subset(acs12, citizen == "yes")
View(non_citizens)
###############
# exercise 6
# h0: p = .5
# ha: p ≠ .5
non_citizens = subset(acs12, citizen == "no")
x = sum(non_citizens$gender == "male")
n = nrow(non_citizens$gender)
phat = x / n
p0 = 0.5
z = (phat - p0) / se
pvalue = 2 * (1 - pnorm(abs(z)))
z = (phat - p0) / se
pvalue = 2 * (1 - pnorm(abs(z)))
n = nrow(non_citizens$gender)
n = nrow(non_citizens)
n = nrow(non_citizens)
phat = x / n
p0 = 0.5
se = sqrt((p0 * (1 - p0)) / n)
z = (phat - p0) / se
pvalue = 2 * (1 - pnorm(abs(z)))
n = length(non_citizens$gender)
phat = x / n
p0 = 0.5
se = sqrt((p0 * (1 - p0)) / n)
z = (phat - p0) / se
pvalue = 2 * (1 - pnorm(abs(z)))
###############
# exercise 7
data(russian_influence_on_us_election_2016)
force(russian_influence_on_us_election_2016)
View(russian_influence_on_us_election_2016)
View(russian_influence_on_us_election_2016)
responses = russian_influence_on_us_election_2016$influence_2016
responses = table(russian_influence_on_us_election_2016$influence_2016)
did_try = responses["Did try"]
n_total = sum(responses)
p1 = responses["Did try"]
did_try = responses["Did try"]
n_total = sum(responses)
phat = did_try / n_total
se = sqrt(phat * (1 - phat) / n)
responses = table(russian_influence_on_us_election_2016$influence_2016)
did_try = responses["Did try"]
n_total = sum(responses)
phat = did_try / n_total
x = did_try
n = n_total
z_p95 = 1.96
se = sqrt(phat * (1 - phat) / n)
ci_upper = phat + z_95 * se
z_p95 = 1.96
c(ci_lower, ci_upper)
ci_lower = phat - z_p95 * se
ci_upper = phat + z_p95 * se
c(ci_lower, ci_upper)
z_95 = 1.96
se = sqrt(phat * (1 - phat) / n)
ci_lower = phat - z_95 * se
ci_upper = phat + z_95 * se
c(ci_lower, ci_upper)
z_99 = 2.576
ci_lower_99 = phat - z_99 * se
ci_upper_99 = phat + z_99 * se
z_95 = 1.96
se = sqrt(phat * (1 - phat) / n)
ci_lower = phat - z_95 * se
ci_upper = phat + z_95 * se
c(ci_lower, ci_upper)
z_99 = 2.576
ci_lower_99 = phat - z_99 * se
ci_upper_99 = phat + z_99 * se
c(ci_lower_99, ci_upper_99)
# problem 1
mu = 6.1
sd = 0.21
n = 34
xbar = 6.07
diff = xbar - mu
se = sd / sqrt(n)
t = diff / se
pnorm(t)
# problem 2
n = 41
xbar = 81.35
sd = 4.52
alpha = 0.05
se = sd / sqrt(n)
df = n - 1
# use qt to find the critical t-value  for 95%
z = qt(0.975, df)
lower = xbar - se * z
upper = xbar + se * z
# use qt to find the critical t-value  for 95%
z = qt(0.975, df)
# problem 3
mu = 270
sd = 20
n = 41
# 95.5 = .955,
.955 + .45
# 95.5 = .955,
.955 + .045
tcrit = (n1 + n2) - 2
z = (xbar - mu) / (sd / sqrt(n))
z = (xbar - mu) / (sd / sqrt(n))
# problem 4
n = 100
sd = 19.54
xbar = 93.7
mu = 90
alpha = 0.05
z = (xbar - mu) / (sd / sqrt(n))
pnorm(z)
1 -pnorm(z)
# part 2
1 - pnorm(z / 2)
# part 2
1 - pnorm(z * 2)
# part 2
1 - pnorm(z / 2)
# part 2
1 - pnorm(z)
# part 2
2 * (1 - pnorm(z))
se = sd / sqrt(n)
moe = se * 31.05
# problem 5
n = 30
mu = 2900
sd = 170
alpha = 0.01
se = sd / sqrt(n)
moe = se * 31.05
alpha = 0.01 / 2
se = sd / sqrt(n)
moe = se * 31.05
# problem 5
n = 30
mu = 2900
sd = 170
alpha = 0.01 / 2
se = sd / sqrt(n)
moe = se * 2.576
se = sd / sqrt(n)
moe = se * 2.576
2900 + moe
2900 - moe
29.9 / 5.916
1 - pnorm(1.47)
# Given values
mu <- 543.6  # Population mean
sigma <- 29.9  # Population standard deviation
X <- 548  # Score to test
# Calculate Z-score
z <- (X - mu) / sigma
# Find the cumulative probability for the Z-score
prob_less_than_548 <- p_
## Given values
mu <- 543.6  # Population mean
sigma <- 29.9  # Population standard deviation
X <- 548  # Score to test
# Calculate Z-score
z <- (X - mu) / sigma
# Find the cumulative probability for the Z-score
prob_less_than_548 <- pnorm(z)
# Calculate probability for 548 or higher
prob_548_or_higher <- 1 - prob_less_than_548
# Print the result
prob_548_or_higher
# Print the result
prob_548_or_higher
View(employed)
z1 - pnorm(1.47)
z - pnorm(1.47)
## Given values
mu <- 543.6  # Population mean
sigma <- 29.9  # Population standard deviation
X <- 548  # Score to test
source("~/Code/school/statistics/webwork/homework/WebWork9.R", echo=TRUE)
## Given values
mu <- 543.6  # Population mean
sigma <- 29.9  # Population standard deviation
X <- 548  # Score to test
# Calculate Z-score
z <- (X - mu) /sigma
## Given values
mu <- 543.6  # Population mean
sigma <- 29.9  # Population standard deviation
X <- 548  # Score to test
# Calculate Z-score
z <- (X - mu) /sigma
# Find the cumulative probability for the Z-score
prob_less_than_548 <- pnorm(z)
# Calculate probability for 548 or higher
prob_548_or_higher <- 1 - prob_less_than_548
df <- c(37257, 34295, 25668, 27890, 36843,
23584, 26146, 31596, 30711, 29662,
33846, 26175, 35611, 31791, 24139)
df
sum(df)
mu = sum(df) / length(df)
n = 100
success = 99
df <- c(37257, 34295, 25668, 27890, 36843,
23584, 26146, 31596, 30711, 29662,
33846, 26175, 35611, 31791, 24139)
mu = sum(df) / length(df)
list <- c(37257, 34295, 25668, 27890, 36843,
23584, 26146, 31596, 30711, 29662,
33846, 26175, 35611, 31791, 24139)
df = n - 1
t_value = qt(0.97, df)
mu = mean(winnings)
sd = sd (winnings)
list <- c(37257, 34295, 25668, 27890, 36843,
23584, 26146, 31596, 30711, 29662,
33846, 26175, 35611, 31791, 24139)
mu = mean(list)
sd = sd (list)
df = n - 1
# two tailed
t_value = qt(0.97, df)
lower = mu - moe
upper = mu + moe
# two tailed
t_value = qt(0.97, df)
moe = t_value * (sd / sqrt(n))
lower = mu - moe
upper = mu + moe
sd = sd(list)
list <- c(37257, 34295, 25668, 27890, 36843,
23584, 26146, 31596, 30711, 29662,
33846, 26175, 35611, 31791, 24139)
mu = mean(list)
sd = sd(list)
n = 100
success = 99
alpha = 0.06
list <- c(37257, 34295, 25668, 27890, 36843,
23584, 26146, 31596, 30711, 29662,
33846, 26175, 35611, 31791, 24139)
mu = mean(list)
sd = sd(list)
df = n - 1
# april 28 notes
library(tidyverse)
library(ggplot2)
data(possum)
library(openintro)
data(possum)
ggplot(data = possum, aes(x = total_l, y = head_l)) +
geom_point()
model = lm(data = possum, head_l ~ total_l)
model = lm(total_l ~ head_l, data = possum)
summary(model)
model = lm(head_l ~ total_l, data = possum)
summary(model)
model = lm(head_l ~ total_l, data = possum)
summary(model)
# residual plot
residuals = resid(model)
plot(fitted(model), residuals)
abline(0,0)
View(possum)
data(honda)
data(honda)
Used_Honda_Civic <- read.csv("~/Downloads/Used_Honda_Civic.csv")
View(Used_Honda_Civic)
View(Used_Honda_Civic)
model = lm(price ~ age, data = Used_Honda_Civic)
summary(model)
residuals = resid(model)
plot(fitted(model), residuals)
abline(0,0)
ggplot(data = Used_Honda_Civic, aes(x = age, y = price)) +
geom_point()
############################################################
library(readxl)
library(dplyr)
setwd("/Users/davidsosa/Code/school/regression-analysis/projects/height-vs-gdp/data/new_data")
data <- read_excel("new_clean_data.xlsx", sheet = 1)
# Clean the data: keep only needed columns
data_clean <- data %>%
select(State, Male_Income, Male_Log_Income, Female_Log_Income, Female_Income, `fixed male height`, `Female Height Fixed`, Pct_Bachelors_or_more, White, Black, Hispanic, Asian, Foreign.Born)
# Rename columns for easier coding
colnames(data_clean) <- c("State", "Male_Income", "Male_Log_Income", "Female_Log_Income", "Female_Income", "Male_Height", "Female_Height", "Pct_Bachelors_or_more", "White", "Black", "Hispanic", "Asian", "Foreign_Born")
# Run regression 1: Male height
model_male <- lm(Male_Log_Income ~ Male_Height + Pct_Bachelors_or_more + White + Black + Hispanic + Asian + Foreign_Born, data = data_clean)
summary(model_male)
model_male <- lm(Male_Income ~ Male_Height + Pct_Bachelors_or_more + White + Black + Hispanic + Asian + Foreign_Born, data = data_clean)
summary(model_male)
